---
title: 앙상블 모델을 이용한 와인 데이터셋 예측 실험
description: 다양한 머신러닝 모델을 앙상블하여 와인 품질 예측 성능을 향상시킨 프로젝트
category: AI
skills:
  - Python
  - Scikit-learn
  - Pandas
  - NumPy
  - XGBoost
  - LightGBM
period: 2024.01 - 2024.02
status: 완료
---

# 앙상블 모델을 이용한 와인 데이터셋 예측 실험

## 프로젝트 개요
다양한 머신러닝 모델을 조합하여 와인의 품질을 예측하는 앙상블 모델을 개발했습니다. 
Random Forest, XGBoost, LightGBM 등의 모델을 활용하여 예측 성능을 향상시켰습니다.

### 1. **프로젝트 제목**
   - 앙상블 모델을 이용한 와인 데이터셋 예측 실험

### 2. **프로젝트 설명 (간단한 개요)**
   - 본 프로젝트는 여러 앙상블 학습 기법을 사용하여 와인 데이터셋의 예측 성능을 비교하는 실험입니다. 다양한 앙상블 모델을 적용하고 성능을 비교함으로써, 각 모델의 장단점을 분석하고 최적의 예측 모델을 도출하는 것을 목표로 합니다.

### 3. **주요 기능 / 특징**
   - UCI 머신러닝 리포지토리의 Wine Dataset을 활용
   - 다양한 앙상블 모델(Random Forest, Gradient Boosting, XGBoost, Stacking Classifier) 적용
   - 학습 데이터(70%)와 테스트 데이터(30%)로 분리하여 모델 성능 평가
   - 정확도(Accuracy) 기반 모델 성능 비교 및 시각화

### 4. **기술 스택**
   - **프로그래밍 언어**: Python
   - **라이브러리**: scikit-learn, XGBoost, matplotlib, seaborn
   - **모델**: Random Forest, Gradient Boosting, XGBoost, Stacking Classifier
   - **데이터 처리**: Pandas, NumPy
   
### 5. **프로젝트 상태**
   - 완료

### 6. **성과 및 결과**
   - 각 모델의 정확도 비교 결과:
     - **Random Forest**: 1.0000
     - **Gradient Boosting**: 0.9074
     - **XGBoost**: 0.9630
     - **Stacking Classifier**: 0.9444
   - Random Forest 모델이 가장 높은 정확도를 기록했으며, XGBoost 및 Stacking Classifier도 우수한 성능을 보였습니다.
   - 다양한 앙상블 모델이 단일 모델보다 높은 성능을 제공할 수 있음을 확인.

### 7. **프로젝트 이미지 / 영상**
   - 모델별 정확도 비교 그래프 및 시각화 자료 추가 예정

### 8. **주요 목표 / 문제 해결**
   - 단일 모델의 한계를 극복하고 예측 성능을 향상시키는 방법 탐구
   - 여러 앙상블 기법을 활용하여 성능 비교 및 최적의 모델 선택
   - 와인 데이터셋과 같은 다중 클래스 분류 문제에서 적절한 머신러닝 기법 탐색

### 9. **팀 구성 (옵션)**
   - 개인 프로젝트

### 10. **프로젝트의 미래 방향성 (옵션)**
   - 다른 데이터셋을 활용한 추가 실험 진행
   - 하이퍼파라미터 최적화 기법 적용을 통한 모델 성능 향상
   - 다양한 평가 지표(F1-score, Precision, Recall) 적용을 통한 모델 분석 강화

